from .types import Tokens

def tokenize_text(text: str) -> Tokens:
    '''Разбиение текста на токены.
    
    Разбиение текста на токены:
    - параграфы (абзацы),
    - предложения,
    - слова
    '''
    
    # TODO

    return {
        "paragraphs": [],
        "sentences": [],
        "words": [],
    }
